{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k01xOBpFiLY-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lVEZesShbTU",
    "outputId": "cd2746c1-8d7c-4663-97b8-8367623ff6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |████▊                           | 10 kB 23.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 20 kB 25.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 30 kB 29.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 40 kB 32.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 51 kB 36.7 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 61 kB 39.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 68 kB 5.7 MB/s \n",
      "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Jovian Commit Essentials\n",
    "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
    "!pip install jovian --upgrade -q\n",
    "import jovian\n",
    "jovian.set_project('2-cross-validation-what-when-and-how-to-implement-it')\n",
    "jovian.set_colab_id('1D1Xi9IzQNRsOZRPHC9Tk6AUnGq829ZiA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXodG8qz0G4s"
   },
   "source": [
    "In this NoteBook, you will learn how to use cross-validation for better measures of model performance.\n",
    "\n",
    "**`Introduction`**\n",
    "\n",
    "Machine learning is an <u><b>iterative</b></u> process.\n",
    "\n",
    "You will face choices about what predictive variables to use, what types of models to use, what arguments to supply to those models, etc. So far, you have made these choices in a data-driven way by measuring model quality with a validation (<i>or that 20% test data</i>) set.\n",
    "\n",
    "But there are some drawbacks to this approach. To see this, imagine you have a dataset with 5000 rows. You will typically keep about 20% of the data as a validation dataset, or 1000 rows. But this leaves some random chance in determining model scores. That is, a model might do well on one set of 1000 rows, even if it would be inaccurate on a different 1000 rows.\n",
    "\n",
    "In general, the larger the validation set, the less randomness (aka \"noise\") there is in our measure of model quality, and the more reliable it will be. Unfortunately, we can only get a large validation set by removing rows from our training data, and smaller training datasets mean worse models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S3rtmHNI0G4v"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFTK2GS00G46"
   },
   "source": [
    "What is cross-validation?\n",
    "--\n",
    "\n",
    "In cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality.\n",
    "\n",
    "For example, we could begin by dividing the data into 5 pieces, each 20% of the full dataset. In this case, we say that we have broken the data into 5 \"folds\".\n",
    "\n",
    "![SuvenML_CrossValidation_Image](https://drive.google.com/uc?id=1F6jNuimRQbnxw0knpRmb1ADuCZ2Zgx-I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVTZOAeV0G48"
   },
   "source": [
    "**`Then, we run one experiment for each fold:`**\n",
    "\n",
    "1. In Experiment 1, we use the first fold as a validation (or holdout) set and everything else as training data. This gives us a measure of model quality based on a 20% holdout set.\n",
    "<br><br>\n",
    "2. In Experiment 2, we hold out data from the second fold (and use everything except the second fold for training the model). The holdout set is then used to get a second estimate of model quality.\n",
    "<br><br>\n",
    "3. We repeat this process, using every fold once as the holdout set. Putting this together, 100% of the data is used as holdout at some point, and we end up with a measure of model quality that is based on all of the rows in the dataset (even if we don't use all rows simultaneously)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jHNe5ZF0G4-"
   },
   "source": [
    "When should you use cross-validation?\n",
    "--\n",
    "\n",
    "Cross-validation gives a more accurate measure of model quality, which is especially important if you are making a lot of modeling decisions. However, **`it can take longer to run`**, because it estimates multiple models (one for each fold).\n",
    "\n",
    "**So, given these <u>tradeoffs</u>, when should you use each approach?**\n",
    "\n",
    "> For small datasets, where extra computational burden isn't a big deal, you should run cross-validation.\n",
    "\n",
    "> For larger datasets, a single validation set is sufficient. Your code will run faster, and you may have enough data that there's little need to re-use some of it for holdout.\n",
    "\n",
    "> There's no simple threshold for what constitutes a large vs. small dataset. But if your model takes a couple minutes or less to run, it's probably worth switching to cross-validation.\n",
    "\n",
    "Alternatively, you can run cross-validation and see if the scores for each experiment seem close. If each experiment yields the same results, a single validation set is probably sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4Rmyl6P0G4_"
   },
   "source": [
    "**`Summarizing till this point`**\n",
    "> Cross-Validation or k-Fold Cross-Validation is a **resampling procedure** used to evaluate machine learning models on a **limited data sample**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4PodmLc0G5B"
   },
   "source": [
    "How to implement it ?\n",
    "--\n",
    "\n",
    "**`The general procedure is as follows`**:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "<br><br>\n",
    "2. Split the dataset into k groups ( usual values of **k** range from 5 to 20 )\n",
    "<br><br>\n",
    "3. For each unique group:\n",
    "<br><br>\n",
    "\n",
    "> a. Take the group as a hold out or test data set\n",
    "\n",
    "> b. Take the remaining groups as a training data set\n",
    "\n",
    "> c. Fit a model on the training set and evaluate it on the test set\n",
    "\n",
    "> d. Retain the evaluation score and discard the model\n",
    "<br>\n",
    "\n",
    "4. Summarize the skill of the model by taking **mean** of model evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpi8m5Js0G5D"
   },
   "source": [
    "## Lets go step by step to understand Cross Validation **practically**. \n",
    "We would **first** run through a <u>concept</u> example and <u>then</u> try and apply over **Iris Data set for finding** : \n",
    "\n",
    "1. Most approriate accuracy for a given model. We would choose KNN classifier.\n",
    "<br><br>\n",
    "2. Search for an optimal value of K for KNN\n",
    "<br><br>\n",
    "3. Better of 2 ML Models. Here we would compare KNN with LogisticRegression.\n",
    "<br><br>\n",
    "and **lastly** \n",
    "<br><br>\n",
    "4. Do feature selection from some `advertising dataset` from **kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3l1L-DXF0G5F",
    "outputId": "0a710f16-d194-4802-da13-e94f634e8ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.1 0.4 0.5 0.6], test: [0.2 0.3]\n",
      "train: [0.2 0.3 0.4 0.6], test: [0.1 0.5]\n",
      "train: [0.1 0.2 0.3 0.5], test: [0.4 0.6]\n"
     ]
    }
   ],
   "source": [
    "###########################   Concept Example  ####################################\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# scikit-learn k-fold cross-validation\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Imagine we have a data sample with 6 observations:\n",
    "ML_data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n",
    "\n",
    "# The first step is to pick a value for k in order to determine the number of folds \n",
    "# used to split the data. Here, we will use a value of k=3.\n",
    "\n",
    "# For example:\n",
    "## Model1: Trained on Fold1 + Fold2, Tested on Fold3\n",
    "## Model2: Trained on Fold2 + Fold3, Tested on Fold1\n",
    "## Model3: Trained on Fold1 + Fold3, Tested on Fold2\n",
    "\n",
    "# We do not have to implement k-fold cross-validation manually. \n",
    "# The scikit-learn library provides an implementation for it.\n",
    "kfold = KFold(3, True, 1)\n",
    "#  Here 3 -> indicates no. of folds, shuffle = True means we want to split shuffled data\n",
    "# and 1 -> is the random_state\n",
    "\n",
    "# we then use the split() function\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(ML_data):\n",
    "\tprint('train: %s, test: %s' % (ML_data[train], ML_data[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXn05wkN0G5L",
    "outputId": "d7dbca29-e6fb-4ec1-b39a-242a8a4d0c83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####   Real Example using Iris dataset. Here I have not used CrossValidation #######\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "#from sklearn.cross_validation import train_test_split   # is changed to sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# read in the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the accuracy changes a lot\n",
    "# this is why testing accuracy is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6)\n",
    "\n",
    "# check classification accuracy of KNN with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVTkhRAn0G5Q"
   },
   "source": [
    "<font color=\"red\">**Question:**</font> What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
    "\n",
    "<font color=\"red\">**Answer:**</font> That's the essense of cross-validation (also called CV)!!\n",
    "\n",
    "`Note` : This is also the <u>first application</u> of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAew5KNd0G5S",
    "outputId": "4bb4ad90-5130-48b7-94d1-c349a3030558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Redo-ing the above example with Cross Validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "# k = 5 for KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Use cross_val_score function\n",
    "# We are passing the entirety of X and y, not X_train or y_train, it takes care of \n",
    "# splitting the data\n",
    "# cv=10 for 10 folds\n",
    "# scoring='accuracy' for evaluation metric - althought their are many\n",
    "ML_KNN_scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(ML_KNN_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l9dAMxZ0G5Y"
   },
   "source": [
    "**`Note`** : In the first iteration, the accuracy is 100%. Second iteration, the accuracy is 93% and so on. \n",
    "\n",
    "So we can report the final , single value of Model metric as **`mean`** of the metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbEt89ld0G5Z",
    "outputId": "5855a1fa-39eb-464e-ef50-e8d513828a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "print(ML_KNN_scores.mean())\n",
    "\n",
    "## This metric of the ML model(i.e 96.66%) is better representative than 97.36%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlQ1lt290G5f"
   },
   "source": [
    "**Can You solve this ?**\n",
    "\n",
    "> Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset\n",
    "\n",
    "`Note` : This is the <u>second application</u> of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqt860RH0G5g",
    "outputId": "d973ad2c-3bce-4c31-fb14-55f269c7cd66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96, 0.9533333333333334, 0.9666666666666666, 0.9666666666666666, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9800000000000001, 0.9666666666666666, 0.9666666666666666, 0.9733333333333334, 0.96, 0.9666666666666666, 0.96, 0.9666666666666666, 0.9533333333333334, 0.9533333333333334, 0.9533333333333334]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "\n",
    "# range of k we want to try\n",
    "k_range = range(1, 31)\n",
    "\n",
    "# empty list to store scores\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    ML_KNN_scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(ML_KNN_scores.mean())\n",
    "\n",
    "\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7Fcyt6P0G5m",
    "outputId": "056fc9d8-4f79-46f8-fe4f-36ac8663029a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list 30\n",
      "Max of list 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# in essence, this is basically running the k-fold cross-validation method 30 times \n",
    "# because we want to run through K values from 1 to 30\n",
    "# we should have 30 scores here\n",
    "print('Length of list', len(k_scores))\n",
    "print('Max of list', max(k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Ex514IKu0G5w",
    "outputId": "47acd7ce-5751-4da9-e3af-6be77c528366"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZhbZ3mwfz+zajweSV7GI9sjL1mcxLE9k9SEnYS0QFIohJQtQAstW/tBC4XwBUrLRwP5aCmUlh+UNqwJBQKELYXQkF9IKJQtDpbiOI4dx1k04xl7vEizWbNIz/fHORrLsqQ5mpFmRtJzX5euOXrPOe95X0lznvM+q6gqhmEYhuGVhsUegGEYhlFdmOAwDMMwSsIEh2EYhlESJjgMwzCMkjDBYRiGYZSECQ7DMAyjJExwGCUjIqMics4cz32diPy43GOa5Zp7ReSKhbymASJyn4i8ucLXuEJE+ip5DeNsTHDUOCLyXyJyY572l4nIoIg0ldqnqi5X1UMerr1JRDT7Gqr6VVV9YanXnA+qerGq3reQ1zSMWsYER+1zC/B6EZGc9j8Cvqqq0147mouQMeaOfd7GUsUER+3zPWAV8NxMg4isAF4C3Coil4nIL0UkLiIDIvJpEWnJOlZF5O0i8ijwaFbbee72i0Vkt4gMi0hMRD6Ude3/dv/GXfXWM0XkjSLy86z+nyUi94tIwv37rKx994nIh0Xkf0RkRER+LCKr3X0+EfkPETnujv1+EenK9wGIyBMi8nvu9odE5Jsicqvb514R2VnowxORf3HnNSwiD4hI9ufYKCJ/LSKPuX09ICJhd9/FInK3iJwQkSMi8tdu+5dF5CNZfZyhanHHeoOIPAiMiUiTiLwv6xoPi8jLc8b4FhHZl7X/UhF5r4h8O+e4T4nIv+SZ4w0icnueeX/K3X6jiBxy+39cRF5X6PMq8jmuFZEHReS9c7j+n2TN75CIvK3IdWZ+m+773M/7JSIScX8zvxCRHTnj6Hevs19EfrfUedYNqmqvGn8BnwM+n/X+bUDE3f4d4BlAE7AJ2Ae8K+tYBe4GVgJtWW3nudtXANtxHkJ2AEeAa9x9m9xjm7L6eyPwc3d7JXASZ/XTBFznvl/l7r8PeAzYArS57/8+aw7/CSwDGt15+AvM/wng99ztDwFJ4Pfd8z4K/KrIZ/d6HMHbBLwHGAR87r73AnuACwABetxjO4AB93if+/7p7jlfBj6S1f8VQF/OWCNAOOvzfiWwzv2MXw2MAWuz9vUDT3PHcB6wEVjrHhd0j2sCjgK/k2eOG4FxoMN93+iO/xlAOzAMXODuWwtc7PF3dx/wZmAzcAB4a4HjCl7fff9i4Fx3fpe7x15a4POb+W3mft7AJe5n8HT3Gm9wP+9W9zuMAeuyfrvnLvb/7lJ92YqjPrgFeIWI+Nz3f+y2oaoPqOqvVHVaVZ8A/h3nnzObj6rqCVU9lduxqt6nqntUNa2qDwJfz3N+IV4MPKqqX3Gv/3XgEeAPso75kqoecK/9TaDXbZ/CuUmfp6opdx7DHq/7c1W9U1VTwFdwbvh5UdX/UNXj7vg+wembDDg3xb9R1f3qEFXV4ziruUFV/YSqJlV1RFV/7XFsAJ9S1Vjm81bVb6nqYfcz/gbOyu+yrDF8TFXvd8dwUFWfVNUBnBXfK93jrgKOqeoDeeb4JPBbILOSuRIYV9Vfue/TwDYRaVPVAVXdW8JctgL3Av9HVW/Od8Bs11fVH6rqY+78fgr8mKwVdAm8Ffh3Vf21+5u5BZjAEZApnO92q4g0q+oTqvrYHK5RF5jgqANU9efAMeAaETkX56bzNQAR2SIiPxDHUD4M/F9gdU4XsUJ9i8jTReReERkSkQTwZ3nOL8Q64MmctieB9VnvB7O2x4Hl7vZXgLuA20TksIh8TESaPV43t0+fFLAniMj1rpokISJxIMDp+YVxVkS5FGr3yhmft4j8cZZ6JQ5s8zAGcO1b7vbrcT6zQnwNZ8UH8Fr3Pao6hrPK+TNgQER+KCIXljCX1+GsiG6f5bi81wcQkatF5Feu2i+Os1r0+hvLZiPwnszn6PYVxlllHATehbMiPSoit4nIujlcoy4wwVE/3Iqz0ng9cJeqHnHbP4vzlH++qvqBv8ZRCWRTLIXy14A7gLCqBoB/yzp/ttTLh3H+mbPZgHOjKYqqTqnq36nqVuBZOE/5fzzbeaXg2jP+N/AqYIWqBoEEp+cXw1Gh5BIDCrkrj+Go1zKE8hwz87mJyEYcVeM7cFR4QeAhD2MAx761Q0S24Xw+Xy1wHMC3gCtEpBvnyX/mxq2qd6nqC3DUVI+44/HKh3AeWr4mIo2lXl9EWoFvAx8Hutz538nZv9EM4xT+fGPATaoazHotc1e6qOrXVPU5OL9JBf6hhHnWFSY46odbgd8D3oKrpnLpwNFhj7pPkn9eYr8dwAlVTYrIZThPixmGcNQchW6idwJbROS1rhH41TiqjR/MdlEReb6IbHdvRsM4qqt0iWOfjQ5gGmceTSLyQcCftf/zwIdF5Hxx2CEiq9zxrxWRd4lIq4h0iMjT3XMiwO+LyEoRCeE85RajHecmNgSOoRhnxZE9hutF5HfcMZznChtUNYnzpP814Deq+lShi6jqEI5N4kvA46q6z71elziu2+04ap1RSvucp3DUZe04zhh57zmFrg+04KiQhoBpEbkaKObOHQFeK47jwlWcqTb9HPBn7ipZRKRdHOeODhG5QESudAVVEjhV4jzrChMcdYJrv/gFzj/wHVm7rse52Y/g/GN9o8Su/xdwo4iMAB/EsUNkrjkO3AT8j6saeEbOmDL2gPcAx3Ge7l+iqsc8XDeEc1McxjHo/5Tiqpi5cBfwXziG3SdxbijZaqR/wpnvj91xfAHHoD0CvADHVjOIY5N4vnvOV4AojlH2x8zyeavqw8AngF/iOB5sB/4na/+3cD7jr+F8h9/DcTrIcIt7jpfP5ms4Dxdfy2prAN6Nszo8gXMj/nNwVmQiMjpbp6o6CVwLdAFfLCQ88l3f/Sz/EudzPonzW70j79kO78T53OM4arLvZfW1C+fB6dNuXwdxnDXAEU5/j7M6GgTWAO+fbW71iqhaISfDqFVEZAOOeilUgvOAYRTFVhyGUaO4T/bvBm4zoWGUE4tMNYwaxLVJHMFRsV21yMMxagxTVRmGYRglYaoqwzAMoyTqQlW1evVq3bRp02IPwzAMo6p44IEHjqlqZ257XQiOTZs2sWvXrsUehmEYRlUhIrmZHQBTVRmGYRglYoLDMAzDKAkTHIZhGEZJmOAwDMMwSsIEh2EYhlESFRUcInKVW4LxoIi8L8/+jSJyjzglJe9zUypn9n1MnLKe+8QpeSlu+++IyB63z5l2wzAMY2GomOBw011/BrgaJ1X2dSKyNeewjwO3quoO4EacMp6IU3f62TilSLfhlMXMpEf+LE6Gy/Pdl6VTMAzDWEAqueK4DDioqofctMq3AS/LOWYr8BN3+96s/YpTqzmTi78ZOCIia3HqSv9KnVwptwLXVHAORh3ywJMnicTiiz2MsjExneLrv3mKVLp86YWSUylu+81TpMvYp1E9VFJwrOfM2gV9nFkSFJy6BNe62y8HOkRklar+EkeQDLivu9zCLuvdfor1CYCIvFVEdonIrqGhoXlPxqgfbvj2g3zgu3sWexhl4849A7z/O3v42aPl+z/4wYMDvO87e9gdO1m2Po3qYbGN49cDl4vIbhxVVD+QEpHzgIuAbhzBcKVbxtMzqnqzqu5U1Z2dnWdFzBtGXoaTUzw2NMojgyOcmkwt9nDKQuQpZ/VUzlVUxBUYh+PJsvVpVA+VFBz9OIXgM3STU0taVQ+r6rWqegnwAbctjrP6+JWqjqrqKPAj4Jnu+d3F+jSM+bCnL4EqpNLK3sOJxR5OWYj0OfOIllFwRGNOn0eGTXDUI5UUHPcD54vIZhFpAV5DTslHEVmdVUby/cAX3e2ncFYiTSLSjLMa2aeqA8CwiDzD9ab6Y+D7FZyDUWdkP5XXgp1jYjrFvsNODadoX4JylFFITqXYN+D0OZAwwVGPVExwqOo08A6cus37gG+q6l4RuVFEXuoedgWwX0QO4NQjvsltvx14DNiDYweJqup/uvv+F/B5nHrBj+GsRgyjLERicTavbmd9sK0mBMe+gREmU2mee/5qToxNEjtxat597j08zLRrFB+0FUddUtHsuKp6J3BnTtsHs7ZvxxESueelgLcV6HMXjouuYZQVVSUSi/Oc81YzOZ0m2lf9giOjnnrDMzfxs0ePEemLs2HVsrL0ec7qdo7YiqMuWWzjuGEsGQaHkwyNTNDTHaAnHCB24hTHRycWe1jzIhqL09nRyuUXdOJrbiiLnSPaFyfk97GjO2ArjjrFBIdhuGS8j3rCQXq6gwBVv+qIxOL0dAdpbmxg27pAWdRvkVicnnCAUKCNo8MTFstRh5jgMAyXSF+c5kZh6zo/27sDNAhEYtXrWZUYn+LQsTEu2eAIwd5wkIf6E0yl0nPu8+TYJE8eH6c3vIKQv5XJVJoT45PlGrJRJZjgMAyXyFNxtq7109rUyLKWJrZ0dVS1gTyzWsqsnnrCQSam0+wfHJlzn5FMn+EAoYAPgEGzc9QdJjgMAyduY09/gt5wcKbtkg1BorF4WVxYF4OMPWNHOAAwM7f5CMNoLI4IbF8foMvvCA6L5ag/THAYBnDw6Cjjkyl6sgRHT3eQxKkpnjw+vogjmzvRvjjndrbj9zUD0L2ijVXtLfMykEdjcc5fs5wOX/PpFYcJjrrDBIdhcDqFxhmCowxP6ItFxrU4ez4iQk84OOf5zPTpqr46l7fSIJhLbh1igsMwcIzgfl8Tm1e1z7Rt6epgWUtjVQqO/vgpjo1OckmW4ABHXXVwaJSR5FTJfcZOnOLk+NSMMGpqbKCzo9VWHHWICQ7DwFHB9ISDNDScrgvW2CBsW18eF9aFJjPmnhzB0RMOogp7+kv3FssYxrPtQCG/z9KO1CEmOIy659Rkiv1HRmZUMNn0hoM8fHiYyem5u7AuBtFYnJamBi4M+c9o7+l2DOVzEYaRp+K0NjVwQahjpq3L7zPjeB1igsOoex46nCCV1jOepDP0hoNMptI8Mji8CCObO9FYgovX+WlpOvNfPLishc2r2+dkII/2xdm+PkBz4+k+QwGfuePWISY4jLonWkCtk91WTeqq6VSaPf2JvCsocFYd0RIDG6dSaR7qT5z1GXX5fQwnp2umdonhDRMcRt2zOxZnfbCNzo7Ws/atC/jo7GitKsFx4Mgop6ZSMxHjufSGgwwOJ0taKewfHGFiOn2W4FhrLrl1iQkOo+6JxuJ51VTgurB2B8taBKnS5EaM5zKXVVTm2FwvrZAbBDiQmH+6dqN6MMFh1DXHRifoO3mKHje6Oh+94QCPDY2ROFW6C+tiEHkqTnBZMxsLpE+/aK2f5kYpWXCsbG+he0XbGe1dAYser0dMcBh1TWYl0RteUfCYzL49fdWR8DDa5wTpOUUyz8bX3MjWtf6SVlHRWJye7sBZfWZWHIOJ6k4/b5SGCQ6jronG4jQIbFvvL3jM9hkX1pMLNaw5MzYxzYEjI3kN/dn0hIPs6Xe8yWZjJDnFwaHRvMK1vbWJjtYmW3HUGSY4jLpmdyzuRogXLoYZaGvmnM72qkixvqc/QVod9VoxerqDjE5M89jQ6Ox99iVQpaA6r8tccusOExxG3aKqRGPxgt5H2fS6OZ6WeqbcGdfiAobxDL0bvBvI80WMZ7M24GPAVhx1hQkOo2554vg4w8npWW+y4Nw0j41OcHiJP1lHYnHCK9tYtfxs1+JsNq9qp8PX5MnOEY3F2bRqGcFlLXn3d/l9luiwzjDBYdQtGZtFr8cVB7Dk3XId1+LChv4MDQ0ys4qajdwsu7mE/D6GRic82UuM2sAEh1G3RGMJlrU0cv6ajlmPvTDkp6WxYUkLjqPDSQ4nkjP5qGajpzvII4MjJKcKR30PJpIcGZ4oqKYCx8aRSivHRs2zql4wwWHULbtjcbatD9DYkN9tNZuWpga2rvOzewkLjkisuC0il55wkFRa2Xu4sNG/UJbdbE675Jq6ql4wwWHUJRPTKfYdHj4rEroYveEge/oSTKeWZqbcaF98JhW8FzJeUrufKiwMI7E4zY3C1rWF3ZUzaUcsvXr9YILDqEseGRhhMnV27qVi9IaDnJpK8ejR2V1YF4NILM6FoQ58zY2ejl/T4WN9sI1okcDGaCzORWv9Rfu02uP1hwkOoy7xooLJpWcJG8jTaeXB2NnZa2ejJxwoGNiYSisP9sVn9Tpb1d5Cc6NYosM6wgSHUZdEY3E6O1pZ56pZvLBp1TICbc0zSQSXEoeOjTEyMe3ZvpGhNxwkduIUx/MYth8bGmVsMjVrnw0NwpoOc8mtJ0xwGHVJZJZ8TvkQEXrCwaI2gcWiVMN4hsxq4sE86qpSVmVdfqs9Xk9UVHCIyFUisl9EDorI+/Ls3ygi94jIgyJyn4h0u+3PF5FI1ispIte4+74sIo9n7eut5ByM2iMxPsWhoTFPEeO59IaDHDgywvjkdAVGNneisTjLW5s4t3N5Sedt7w7QIOT1FovE4nT4mjhndfus/YQCPhMcdUTFBIeINAKfAa4GtgLXicjWnMM+DtyqqjuAG4GPAqjqvaraq6q9wJXAOPDjrPPem9mvqpFKzcGoTR7s95aWIx+94QBphYf6l1Yp2UxZVy+uxdksa2liS1dHXruNkxE3SIOHPkP+NgYTySWfksUoD5VccVwGHFTVQ6o6CdwGvCznmK3AT9zte/PsB3gF8CNVHa/YSI26InOT3O4xUC6bjLBZSplyk1Mp9g0Ml2wYz9AbDhLtOzMPV3IqxSODI0XrlGQTCrQyPpliZGJprcSMylBJwbEeiGW973PbsokC17rbLwc6RGRVzjGvAb6e03aTq976pIjkTcojIm8VkV0ismtoaGhuMzBqkkgszrmd7QTamks+d9XyVsIr20qu2V1JHh4YZiqlJds3MvSGg8THp3jy+Olns4fclOte0pdAlkuuGcjrglkFR54beTm5HrhcRHYDlwP9wEz+AxFZC2wH7so65/3AhcDTgJXADfk6VtWbVXWnqu7s7Oys0PCNakNViczBbTWbnm5vOZ4WishTczOMZ5hxM87yFpsxjHtclc1Ej5udoy7wsuL4lYh8S0R+X0pxQXGEQDjrfbfbNoOqHlbVa1X1EuADblv2f+SrgO+q6lTWOQPqMAF8CUclZhie6I+f4tho8dxLs9EbDtIfP8XRkaVxk4z2xenytxIqwbU4m/PXLKetufEMb7FILM66gI81fm99Zq5taUfqAy+CYwtwM/BHwKMi8n9FZIuH8+4HzheRzSLSgqNyuiP7ABFZLSKZMbwf+GJOH9eRo6ZyVyG4Quwa4CEPYzEMgBkV03wFB8CDS0Rd5WTEnft8mhob2N4dOGPFEe2Le8oanKHL8lXVFbMKDvfp/m5VvQ54C/AG4Dci8lMReWaR86aBd+ComfYB31TVvSJyo4i81D3sCmC/iBwAuoCbMueLyCacFctPc7r+qojsAfYAq4GPeJmoYYBzQ2xpauDCUOHcS7Nx8TrHe2kpqKtOjk3yxPHxeanewBGGew8PMzmd5vjoBLETp0ryOvM1N7JiWbOpquqEwvUyXVwbx+txVhxHgL/AWTn0At8CNhc6V1XvBO7Maftg1vbtwO0Fzn2Cs43pqOqVs43ZMAoReSrOxev8tDTN3S+kraWRC0MdSyKCPDpLdT6v9IaDTE6neWRweCY9eqnCqMvvs3xVdYKX/55fAn7gGlV9sap+R1WnVXUX8G+VHZ5hlI/pVJo9/Yk5xW/k0hMOEo3FSS9y8aJoLIEIbPeYEbcQ2Xm4IrEEDXPo04IA6wcvguMCVf2wqvbl7lDVf6jAmAyjIjx6dJRTU7PnXvJCb3eQ4eQ0jx8fK8PI5k4kdpLzOpfT4SvdtTibdQEfq5e3EokliMbibOnqoL11VoXEGYT8PgYTVsypHvAiOH4sIjP/aSKyQkTuKnaCYSxF5prPKR8Zw/FiZspVVaJ9ibLMR8QpJbs7dtIxjM+hzy6/j2OjE0xOL816JUb58CI4OrNdZFX1JLCmckMyjMoQjcUJtDWzcdWyefd1budy2lsaF9VAHjtxihNjk/M2jGfoDQc4NDRGfHxqTn1mCjotFTdlo3J4ERwpEdmQeSMiGwFLSGNUHZFYnJ5waRlxC9HYII4L6yIKjkiZDOMZsoXFXOxAXQEr6FQveFFifgD4uYj8FBDgucBbKzoqoyZRVVTxlDSv3IxNTHPgyAgvvDhUtj57wyv4ws8PMZA4RVPDwlco+M3jx2ltauCCUEdZ+tvhCou25ka2dJWWZReya49X3s6RTisilOUhwCidWQWHqv6XiFwKPMNtepeqHqvssIxa5C++vhtV+MzrLl3waz/UnyCt3lNoeOGSDUGmUsozP/qT2Q+uEDs3rqC5sTxCK9DWzHlrlrOqvYWmOfS5kGlH3vjl+9m4chkfvmZbxa9lnI1Xt4kUcBTwAVtFBFX978oNy6g10mnlpweGQJ3thV51lNMwnuHKC9fw8Vf2cGoqNfvBFeIZm1eWtb/PvPZSWucY4xJc1kxLU0PFVVXJqRS/fOwYw6fK9xBglIaXAMA3A+/EyTUVwVl5/BKnToZheOLx42OMJJ2U24eOjXLemvKoV7wS7YsTXtnGquV5kynPiebGBl7xO91l628pMB+1l4iwNuBjoMJpRzLZgM2Wsnh4ebR4J04m2idV9fnAJcDih8waVUW2ETmyCDmeorHyBP4ZxenyV772eOa3dHRkgtQiB2DWK14ER1JVkwAi0qqqjwAXVHZYRq0RicVpb2lkeWvTghdBOjqSpD9+qqxqKiM/IX/lo8czasdUWjk+agGHi4EXG0efGwD4PeBuETkJPFnZYRm1RjQWZ0d3EBEWvAhSOTLiGt4IBXwM7nVKyFbK4ykai7OspZHxyRQDiaTn1O9G+fCSHfflqhpX1Q8Bfwt8ASeduWF4IjmV4mG3tGlPOMi+gWGSC2hQjsbiNDYIF68zY2ql6fL7mJxOEx+fmv3gOZDJBvz8C5wYZMuNtTgUFRwi0igij2Teq+pPVfUOt4a4YXhiX1Zp095wkOm0svfw8IJdPxKLc2Gog7aWxgW7Zr2SccmtlIE8kw34RduceBwzkC8ORQWHqqZw6mVsKHacYRQjmuUK2xte2BxP6bQS7YuXLS2HUZxQhaPHM9mAr7igk6YGscJRi4QXG8cKYK+I/AaYSQWqqi8tfIphnCYSO7O0acjvW7AcT4eOOW7AveZRtSDMlJCtkOCIxE5y/prl+H3NdC2AId7IjxfB8bcVH4VR0+RmcO0NBxesCNLMaqeEMqjG3FnT0YpIZUrIZrIB/95Fjn2jy99qK45FwkvKkdzSrYbhmfj4JI8fG+OVO08HyvWEg/zX3kFOjk2yor2loteP9jluwOd2lp57ySid5sYGVrW3VkRV1XfyzGzAoYCPRwZHyn4dY3Zm9aoSkRERGXZfSRFJicjCWTaNqibad7YrbGY7sgCrjojrBty4CIkV65VQoLUixvHd7uoxE8i5EMGGRn68uON2qKpfVf1AG/CHwL9WfGRGTRCNxc8qbbq9O+DGc1RWcCSnUuxz3YCNhSPkb6vIiiMai+NrPp0NOOT3MTaZYiRZGddfozAlZTNTh+8BL6rQeIwaIxKLn1XadHlrE+evWV5xA/lpN2CL31hIQoHWihitI7E429YFZrIBV9qDyyiMlySH12a9bQB2AvZNGbOiqkRjca688OyCkb3hIHc/fKSiEcanM+KuqEj/Rn5Cfh/x8SmSUyl8zeWJnZlKpXmoP8Hrn7HxjOuAEzOy0Ekz6x0vK44/yHq9CBgBXlbJQRm1Qd/JUxwvUNq0Jxzk5PgUsROnKnb9aI4bsLEwdPnLvxLYPzjCxHT6DFvZjOuv2TkWHC9eVX+yEAMxao9iNTAyBs7dsZNsKEMN8HxE+ywj7mKQuaEPJJJsXNVelj7z/ZYqIaAMb3jxqrrFTXKYeb9CRL5Y2WEZtUA0Fi9Y2vSCUAe+5oaKJTzMuAFb/MbCE6rADT0ai7OyvYXuFW0zbb7mRoLLmi0IcBHwoqraoaozVkxVPYlTk8MwihKJxdm2PpC3tGlzYwPb1gUqlmJ9xg3YVhwLTiVUSJFYnN5w8Cx7WMjvW5Aa58aZeBEcDSIyY10UkZV4Lzlr1ClTqTQPHU4UTWXeGw7y0OFhplLpsl8/8pTrBlzGGuOGNzp8zbS3NJZtJTCSnOLg0GhetWMo4GNwuHJ2MiM/XgTHJ4BfisiHReTDwC+Aj1V2WEa1c+DICMmpdNEYip5wkMnpNPsrEP0b7TvbDdhYOLoCvrKpqvb0J1CFnjxu1bbiWBy8BADeClwLHHFf16rqV7x0LiJXich+ETkoIu/Ls3+jiNwjIg+KyH0i0u22P19EIlmvpIhc4+7bLCK/dvv8hohUNmeFMSdmjJlFVEWZ1cjuMsdzZNyALfBv8XBu6OURHMWcLLr8Po6PTVRk1WoUxotx/BlATFU/raqfxqkI+HQP5zUCnwGuBrYC14nI1pzDPg7cqqo7gBuBjwKo6r2q2quqvcCVwDjwY/ecfwA+qarnASeBN3mYp7HAZIyZ4ZVtBY/pXtHGqvaWskeQZ9yAreLf4lFOwRGNxdm0ahnBZWc/I4YCPlSd+uPGwuFFVfVZYDTr/ajbNhuXAQdV9ZBb+Ok2zo7/2Ar8xN2+N89+gFcAP1LVcXEsY1cCt7v7bsGqES5JorEEPd2BosF9IkJPOFh2wVHsCdVYGEIBH0dHJkindd59RWOJgqvHjAeXxXIsLF4Eh6jqzLevqmm8GcfXA7Gs931uWzZRHDUYwMuBDhFZlXPMa4Cvu9urgLiqThfp0xm0yFtFZJeI7BoaGvIwXKNcjE5Mc+DoiCdVUU93kINDo2XNN1TMDdhYGEIBH9Np5djY/FYCg4kkg8PJgg8BXSY4FgUvguOQiPyliDS7r3cCh8p0/euBy0VkN3A50A/MFKMWkbXAduCuUjtW1ZtVdaeq7uzs7CzTcA0v7OlzjJlenvh7NwRRdc4pF8XcgI2FYYjpqZIAACAASURBVCY4b56G68zqsdBDyNoKF44y8uPlP+vPgGfh3NT7gKcDb/VwXj8Qznrf7bbNoKqHVfVaVb0E+IDblq23eBXwXVXNPI4eB4IiklnxnNWnsfhEctJfF6PHdZctl4E84wZsEeOLy4wKaZ439EgsTnOjsHWtP+/+4LJmWpoaLHp8gfGScuQojrqoVO4HzheRzTg399cAr80+QERWAydc9df7gdyI9Ovc9sxYVETuxbF73Aa8Afj+HMZmVJCMMdNLkabgshY2r24vm50j4wZsEeOLy+kgwPnFWERjcS5a6y+YLFFEymqIN7zhxavKJyJvF5F/FZEvZl6znefaId6Bo2baB3xTVfeKyI0ikqlXfgWwX0QOAF3ATVnX3YSzYsmtQHgD8G4ROYhj8/jCbGMxFpZoX2musD3dgbKVkvXiBmxUntXLW2lskHmtOFJpZU//7KvHkNUeX3C8GLm/AjyCkxn3RuB1OIJgVlT1TuDOnLYPZm3fzmkPqdxznyCP4VtVD+F4bBlLkCPDSQYSyZJURT3hIN+LHGYgcYq1gcLuu17w4gZsVJ7GBmFNR+u8gvMeGxpldGJ6VltZV8DHgwtUw95w8GLjOE9V/xYYU9VbgBfj2DkM4yxmnvhLUBVlbgzlUFd5cQM2FoYu//yix2czjGdYG/AxkEiS5fxpVBgvgiNjmI6LyDYgAJxdmccwcP7ZmxoKGzPzcdFaP82NMm8DeSluwEblma8KKRKL0+Fr4pzVxVOzd/l9TE6niY9bCdmFwovguNlNcvg3wB3AwzjR24ZxFrMZM/Pha27korX+ea84Mm7AJjiWBqHA/IzW0Vicnu4gDQ3FV4/l8uAyvOMlV9XnVfWkqv63qp6jqmtU9d8XYnBGdZFOKw/2Fc+IW4jecJA9fQlS84g0NsP40qLL72N0YprRienZD84hOZXikcGRvIkNcwkFWgETHAuJRUgZZSNjzJzLE39Pd5CxyRQHj47OfnABorE4Gz26ARuVZ+086nI81O88RHhxsjgdbGiCY6EwwWGUjfnkiMoY0+ejror2xS0/1RJiPqVdS/ktrek4XarWWBhMcBhlI9oXp6N1dmNmPjavaqfD10Rkjm6Vc3EDNirLfCoBRvsSrAv4WOMKn2K0NDWwenmrRY8vIAXjOETk2kL7AFT1O+UfjlHNRGJxdoQDsxoz89HQIPR0B4k8NTfB4dV101g45mO0jsROlvRdhgKtZuNYQIqtOP7Afb0JJzr7de7r88CfVn5oRjWRnErxyMDIvFRFveEg+4+McGoyNfvBOURdN+CL13l3AzYqS1tLI35fU8krjuOjE8ROnCrpt2RpRxaWgoJDVf9EVf8EaAa2quofquofAhe7bYYxw97DCaY9GjML0RMOkkorDx0uPVNuZA5uwEblWRtoK3klkEk/U8qKY77BhkZpeLFxhFV1IOv9EWBDhcZjVCmRmHOzn8+KI+N6WaqBPOMG7MV101hY5lJ7PBJL0CCwfb337zPk93FyfIrkVOmrVaN0vOSqukdE7uJ0MaVXA/9/5YZkVCPRWNyzMbMQazp8rA+2zdgrvHLoWCan0Yo5X9uoDCF/K48MDJd0TjQWZ0tXB+2tXm5P7nUCpz24Nq4q3TnDKA0vAYDvAP4N6HFfN6vqX1R6YEZ1EYmVlhG3ED3hQMmCY/dTGddNW3EsNUJ+H0OjE0yl0p6OV1Unu3KJKs/5eHAZpePVHfe3wA9V9a+Au0TEanIaM5wYm+SpE+NliaHoDQfpO3mKY6Pes6qedgNePu/rG+WlK+BDFYZGvH2fTx4fJz4+VXI9FUs7srB4qcfxFpzU55k0I+uB71VyUEZ1ES2jK2zmSbMUO8d83ICNylLqDb2U6pHZdAXmHmxolI6XFcfbgWcDwwCq+iiWHdfIIhKLl2zMLMS29QEaxLvgyLgBW+Df0mTG9uBRhRSJxWlrbmRLV2mrx47WJpa1NFr0+ALhRXBMqOpk5o1b79sS3xszRPtKN2YWor21iS1dHUT6vLnk7j08zHRaLdXIEqXUFUe0L8729QGaGktLapEpIWsrjoXBy7fzUxH5a6BNRF4AfAv4z8oOy6gWVHUm/XW56A0HicbingrzzCc/llF5Vra30NLY4ElwTE6n2Xt4eM5u1fNN4254x8sj4vtwosf3AG8D7lTVz1V0VDXMj/YMcEf08GIPo2xMpdKcHJ8qa6qPnnCQ2+6P8eZbdtHSVPzZZu/hYdbO0w3YqBwiwhp/Kz+IDvDU8fGix45PppicTs/5txTy+/j14yfmdC7At3bFWLW8hSsv7JpzH/n67Oxo5YoLaku770Vw/IWq/gswIyxE5J1um1EiX/j54+wbGGb9itqpid3THeCKCzrL1t8VF3TSEw4SO1n8RgPga27g1U8Ll+3aRvl5+SXruWvvII8NzZ4y/9INQZ597uo5XScTbJhOa8mOEqrKR364j02r28smONJp5cM/eJiecLAuBccbgFwh8cY8bYYHBhJJXnhxiE++unexh7JkWRto4/tvf/ZiD8MoE+954QW854UXVPw6Ib+P6bRybGxiJtW6V548Pk7i1BT7Dg8zMZ2itWn+qWueOD7GcHK6Ju0uxbLjXge8FtgsIndk7eoA5r4erGPSaeXoSHLG08QwjPJxuqBT6YIjYyubTKXZN89knbl91qLdpdiK4xfAALAa+ERW+wjwYCUHVaucGJ9kKqUzniaGYZSPmYqDw0m2U5qBPeJmV55OO84e5RAcGZfy4eQ0pyZTtLXUTgLOgoJDVZ8EngSeuXDDqW0yTx5dJjgMo+yEAnOPHo/2xbl0wwoePz42ryqU2WS7lA8OJ9k8hwJnSxUvkePPEJH7RWRURCZFJCUipWUtM4DTUa2mqjKM8rN6eSuNDVJy7fGMG3DvhiC94WDJudLyMTGdYt/h4Zmg2FpTV3mJ4/g0cB3wKNAGvBn4TCUHVatkolpNVWUY5aexQehc3lpy9Pgjg8OOG3C3IzgOHRsjMT41r7HsGxhhMpXmqm0hAAaHT82rv6WGp/BMVT0INKpqSlW/BFxV2WHVJkeGkzQIrF7esthDMYyaZC71P07nWguczpXWN79VR+SpkwC86GLHtXcw4T1pZzXgxR13XERagIiIfAzHYF5aPgADcJarazp8JadTMAzDGyF/K48NjZV0zu5YnNXLW1kfbMPf5hQ3jcbiPG/L3GOTon0J1nS0cm7ncpa3NtWcS66XO9gfAY3AO4AxIAz8oZfOReQqEdkvIgdF5H159m8UkXtE5EERuU9EurP2bRCRH4vIPhF5WEQ2ue1fFpHHRSTivqomIGJwODmTxdMwjPKzNtBWso3D8aIKICL4fc2c29k+7xVHxjNLROjyt9afjUNVn1TVU6o6rKp/p6rvdlVXRRGRRhxbyNXAVuA6Edmac9jHgVtVdQdwI/DRrH23Av+oqhcBlwFHs/a9V1V73VdktrEsFY4MJwn5Wxd7GIZRs3T5fYxMTDM2Me3p+OHkFI8NjZ3hftsbXkHEY660fCTGpzh0bGwmdcpc6q4vdQoKDhHZ464E8r489H0ZcFBVD7nZdW8DXpZzzFbgJ+72vZn9roBpUtW7AVR1VFVnzz+xxBlIJM0wbhgVJBRwHsy83qgfjDkusz1nCI4Ax0Yn6Y/PzaCdWa1khFFXDWbtLbbieAnwB8B/ua/Xua8fAXd66Hs9EMt63+e2ZRMFrnW3Xw50iMgqYAsQF5HviMhuEflHdwWT4SZXgH1SRPI+wovIW0Vkl4jsGhoa8jDcyjI+Oc1IctpUVYZRQTIxUl5VQ5mb/I6s7M4ZIRKNeUvtf1afsTgisL3bccUNBVo5OjJBKl071SgKCg5XRfUk8AJV/d+qusd93QC8sEzXvx64XER2A5cD/UAKx2j/XHf/04BzcPJjAbwfuNBtXwncUGD8N6vqTlXd2dlZvgR8c2XQXHENo+KEShQcu5+Kc05nOwHXKA5wYchPS1MDkdjJOY0hEotzbudy/L7mmTGl0lpSOeSljhfjuIjIs7PePMvjef04hvQM3W7bDKp6WFWvVdVLgA+4bXGc1UnEVXNN45SqvdTdP6AOE8CXcFRiS55BC/4zjIpTSvS4qhKJxenNqSXT0tTAxev8c1pxqCrRvjNTlpS6CqoGvAiANwH/KiJPiMiTwL8Cf+rhvPuB80Vks+vO+xogO1kiIrJaRDJjeD/wxaxzgyKSWSpcCTzsnrPW/SvANcBDHsay6MxEjduKwzAqxrKWJvw+b+6vA4kkx0Yn8tb/6OkOsqc/wXQqXdL1++OnODY6eUafawNOCYVaMpB78ap6QFV7gB5gh+vJ9FsP503juPDeBewDvqmqe0XkRhF5qXvYFcB+ETkAdAE3ueemcNRU94jIHkA4XQ/kq27bHpwEjB/xPNtFJBMAZCsOw6gsXisBFqseecmGIKemUhw4MnsNkbx9Zq1iulyDfS0ZyIulVX+9qv6HiLw7px0AVf2n2TpX1TvJMaSr6geztm8Hbi9w7t3AjjztV8523aXIYOIUHb4mlrXMvy63YRiF6fL7PD3dR2NxWhobuHBtx1n7siPIt67ze752NBanpenMPle3t9LUICWnQlnKFFtxZFI5dhR4GSUwOGyuuIaxEIT83lccF63z5y3atHHVMoLLmok8VVogYCQWZ9s6P81Z2SEaGoQ1Ha0lByYuZYqlVf939+/fLdxwapfB4QlTUxnGAhAK+Dg2OsF0Kl0wvU8qrezpT/CqnfnLDosIPd3BkiLIp1Np9vQnuO6yDWft6wp4WwVVC8VUVZ8qdqKq/mX5h1O7HEkk2bJmbrWUDcPwTijgI60wNDoxY5jO5dGjI4xPpugJFy741BMO8umfPMrYxDTtrbOrmA8cGSU5lc5rM1kb8PHI4Ij3SSxxin0aDyzYKGqc6VSaoVFbcRjGQpAdy1FIcERnDOMrCvZzSThIWmFPf4JnnLNq1usWM7Z3+X38dP/iByKXi2KqqlsWciC1zLHRSVJptcp/hrEAeImbiMTi+H1NbFq1rOAxO9zI72gs7klwRGNxVixrZsPKs/sM+X2MTaYYSU7R4WvOc3Z1Mev6y42luAEnr9TMna9avZsWg0GL4TCMBcNLEGAklqDHzV5biFXLWwmvbPNs54j2xQv2OTOmRLImBIeXAMCv4sRhbAb+DngCJ0DP8MhMuhFTVRlGxVm5rIXmRikoOMYnpzlwZIRL8qiUcukNr/DkWTU24fTZ052/z5lVUI0YyL0IjlWq+gVgSlV/qqp/ihPJbXjEao0bxsLR0CBORtoCqqqH+odJpTVvxHguPd0BDieSHJ3lhr+nP0Fa89s3oPQcWksdL4IjU3x3QEReLCKX4CQXNDwyOJykuVFYucxKxhrGQhAqEgR4ulSslxWHc0zG8F2IyCx9Zh4aayV63Ivg+IiIBID34KQB+TzwVxUdVY1xxC0Z29BQWJ9qGEb56CqSdiQSi9O9oo3Vy2cvqrZtfYDGBpnVzhGNxdmwchkr2/M/HPqaGwkua64ZVZWX/Be/VtUEkACeX+Hx1CQDiaSpqQxjAQn5fdyz7wiqepaxOhKL07th9tUGODf8C0Mds2bKjcbi7NxUXBHjRLTXRmp1LyuO/3Frf79JRAo7PRsFOWLpRgxjQQn5fSSn0gyfOrOE7NDIBP3xU54M4xl6w0GisTjpAoWYjg4nOZxIzqr6cnJoza2q4FLDS3bcLcDfABcDD4jID0Tk9RUfWY2gqk6eKltxGMaC0VXAJbcU+0aGnnCQkYlpDh0by7v/dOBf4Sh0qL8VB6r6G1V9N07RpBOABQd6ZGRimvHJlK04DGMBWVtIcPTFaWwQtq0rfpPPpnemlGx+O0e0L05Tg3DxLH2GAj6Oj00wVWKNj6XIrIJDRPwi8gYR+RHwC2CAKqm6txTIuARarXHDWDhOu7+eqRqKxOJc0NVBW8vZGXELcW7ncpa3NhX0rIrE4ly4tgNfc/E+QwEfqnB0pPpXHV5WHFGgF7hRVbeo6g2qanmsPDJgtcYNY8FZ43c8prJVQ+m0Eo3FS1JTATQ2CNvXB/J6VqXTyoOxRMHAv2xqKZbDi+A4R1X/SlV/KSIvqfiIagxLN2IYC09rUyMr21vOUFU9cXyM4eT0rLaIfPSEg+wbGCY5lTqj/dCxUUYmpgsG/mVTS7XHvRjHs10JbqzgWGqSjKoq8wRkGMbC0OX3nRFwl1kxFMuIW4jecJCplPLwwPAZ7RHXTdeL4PCSQ6ta8GQcz8Ii2EpkcDjJyvaWWfWfhmGUl7U5QYCRp+K0tzRy3prlJfdVyEAejcVZ3trEOZ2z97liWTMtTQ01ET1equB4W0VGUcMcGU5aOnXDWARyVxyRvgTbu51I8FIJBXyE/L6zDOSRWJwdHvsUEc9lbZc6XryqXikimRrjLxKR74jIpRUeV83g1Bo3NZVhLDQhv4/jY5NMTKeYmE6x7/BwyYbxbHrCgTNWHMmpFPsGSuuzWA6tasLLiuNvVXVERJ6DkxX3C8BnKzus2mHQ0o0YxqIQCjgPbEeHJ9g3MMJkKk2vB++nQvSEgzxxfJz4+CQADw8MM51WTx5VGboCvrpRVWXcCF4MfE5VfwhYmlcPTE6nOTY6aaoqw1gEsmtgzJSK9ZijKh+5mXIzdTouKaHPkL+VgUSSM32Oqg8vgqNfRP4deDVwp4i0ejyv7jk6Yq64hrFYZOqNDyaSRGJx1nS0zut/cfv6ACLMJDyM9sUJ+X0lPRiGAm1MTqeJj0/NfvASxosAeBVwF/AiVY3j1OJ4b0VHVSNYASfDWDwyQuKIu+KYrVTsbHT4mjmvczmR2EnAzbJbos0kVCOVAL0IjrXAD1X1URG5Angl8JuKjqpGyEStmuAwjIXH39aEr7mB/YMjHDo2VvJNPh+94SDRvgQnxiZ58vh4ycb2jN2lHgTHt4GUiJwH3AyEga9VdFQ1woCbJ8dUVYax8GTcX+955CjgLUhvNnrCQU6MTfLDPQPu+9Ki0DNqrUJlbasFL4IjrarTwLXA/6eq78VZhRizcGQ4SWtTA4G25sUeimHUJV1+HyfGJhGB7d2lpxrJJSN8bv3FE4jAjhK9tNZ0OIJjoA4Ex5SIXAf8MfADt83TnVBErhKR/SJyUETel2f/RhG5R0QeFJH7RKQ7a98Gt4DUPhF5WEQ2ue2bReTXbp/fEJEl6+E1ODxBKOCbl17VMIy5k1ETn9u5HL9v/g9wF4Q6aG1q4NGjo5y/xsmaWwotTQ2sXt5a9S65XgTHnwDPBG5S1cdFZDPwldlOEpFG4DPA1cBW4DoR2Zpz2MeBW1V1B04erI9m7bsV+EdVvQgnjftRt/0fgE+q6nnASeBNHuawKBxJWOU/w1hMMoKjlFiLYjQ3NrBtfWBefYYCrbVv41DVh4HrgT0isg3oU9V/8ND3ZcBBVT2kqpPAbcDLco7ZCvzE3b43s98VME2qerc7hlFVHRfn0f1K4Hb3nFuAazyMZU48fmyM3z51cs7nW+U/w1hcMg9u84nfyCWjrpprn7WQdsRLypErgEdxVg//ChwQked56Hs9EMt63+e2ZRPFsZ0AvBzoEJFVwBYg7qY32S0i/+iuYFYBcdfmUqjPzLjfKiK7RGTX0NCQh+GezQe//xB/892H5nTuTMlYW3EYxqJxbudyROCyTSvL1ufTN69EBJ42xz5zc2hVI15UVZ8AXqiql6vq84AXAZ8s0/WvBy4Xkd3A5UA/TqR6E/Bcd//TgHOAN5bSsarerKo7VXVnZ2fnnAbX0x1k/5ERTk2mZj84h5PjU0xOpy1q3DAWkeeev5r7rr+CC0Idsx/skRds7eK+669gS9fc+gz5fZwcnzqrtkc14UVwNKvq/swbVT2AN+N4P47rboZut20GVT2sqteq6iXAB9y2OM5KIuKquaaB7wGXAseBoIg0FeqznPSGg6TSykOHEyWfm1mKmqrKMBYPEWHjqvYl1WfmnlDNqw4vguMBEfm8iFzhvj4H7PJw3v3A+a4XVAvwGuCO7ANEZLWIZMbwfuCLWecGRSSzVLgSeNgtKnUv8Aq3/Q3A9z2MZU7scH20CxWpL0bmR2ErDsMwspkp6FTFdg4vguPPgIeBv3RfDwN/PttJ7krhHTjpSvYB31TVvSJyo4i81D3sCmC/iBwAuoCb3HNTOGqqe0RkD04Bqc+559wAvFtEDuLYPL7gYQ5zYk2Hj/XBNnbPQXBkvCbW2orDMIwsaiHtSFEnZNcgHVXVC4F/KrVzVb0TuDOn7YNZ27dz2kMq99y7gR152g/heGwtCL3h4JxWHIOJJCLQ2WG1OAzDOE1Xrauq3Cf//SKyYYHGs+ToCQfoO3mKY6MTJZ03mEiyenkrzY2WSNgwjNN0tDaxrKVxJpddNeIl7HEFsFdEfgOMZRpV9aWFT6kdMkE+0Vic372oy/N55oprGEY+Mjm0qnnF4UVw/G3FR7GE2d4doEFKFxxHhpN0r1hWwZEZhlGthAK+mSSo1UhBweFmw+1S1Z/mtD8HGKj0wJYKy1qa2NLVUbKBfHA4yc5NKyo0KsMwqpmQ38evHz+x2MOYM8UU8P8MDOdpT7j76oZLNjgGcq/lHpNTKeLjUzMVyAzDMLLJ1B5Pp6uzhGwxwdGlqntyG922TRUb0RKkpzvIcHKaJ46PezreYjgMwyhGyO9jOq0cH5tc7KHMiWKCo1gGr7p6lO6ZKVLvLeFhJte+GccNw8hHl7+6XXKLCY5dIvKW3EYReTPwQOWGtPTY0tXBspbGmSL1s3G61rjFcBiGcTaZwOBqLehUzKvqXcB3ReR1nBYUO4EWnEy2dUNjg7BtfYCIRwN5JpWAqaoMw8jHTNqRKl1xFBQcqnoEeJaIPB/Y5jb/UFV/UuicWqY3HOTL//MEE9MpWpsaix47OJxkeWsTHWWoOGYYRu2xenkrjQ1StbXHZ43jUNV7cRIL1jW94SCTqTSPDIzM2DwKcWQ4SZff1FSGYeSnsUHoXF69lQAtH4ZHThvIZ1dXDSSs8p9hGMXJuORWIyY4PLIu4KOzo9VTwsMjiaTZNwzDKMraKi4ha4LDIyJCT3eQSF9xwZFOK0dHJswV1zCMooQCJjjqgt5wgENDYyTGpwoec2xsgum0mqrKMIyidPl9jExMMzYxvdhDKRkTHCXQG3ZyTz3YX3jVccRNlWwrDsMwipGJ86pGA7kJjhLY3j17KdnBYas1bhjG7MxEj1ehusoERwkE2po5p7O9qGfVoJsq2VYchmEUI5ME1VYcdUBvOEgkliiYKXdwOEljg7BqucVxGIZRmGquPW6Co0R6w0GOjU7QH89fhGUwMcGaDicq1DAMoxBtLY34fU1V6VllgqNEesOZUrL5Ex4eGbbgP8MwvFGtLrkmOErkwpCflsYGogXiOazWuGEYXumq0trjJjhKpKWpga3r/ESeKiA4LGrcMAyPrA34zMZRL/SGg+zpTzCdSp/RPjoxzejEtKmqDMPwRMjvY2hk4qx7yVLHBMcc6A0HOTWV4sCR0TPaB63yn2EYJdAV8JFWGBqdWOyhlIQJjjmQyZSba+ewWuOGYZTCjEtulRnITXDMgU2rlhFoaz4rgjzz5a81VZVhGB6o1trjJjjmgIjQEw6eFUFu6UYMwyiFzEOmrTiyEJGrRGS/iBwUkffl2b9RRO4RkQdF5D4R6c7alxKRiPu6I6v9yyLyeNa+3krOoRC94SAHjoyckdlyMJEk0NaMr7l4aVnDMAyAle0ttDQ2MDhsNg4ARKQR+AxwNbAVuE5EtuYc9nHgVlXdAdwIfDRr3ylV7XVfL805771Z+yKVmkMxesMB0goP9Z8OBLQYDsMwSkFEWONvNVVVFpcBB1X1kKpOArcBL8s5ZivwE3f73jz7lyw93WeXkj0ynKTL1FSGYZRAyO9jIJE/hdFSpZKCYz0Qy3rf57ZlEwWudbdfDnSIyCr3vU9EdonIr0TkmpzzbnLVW58UkUXJJrhqeSvhlW1neFYNJpKE/Jbc0DAM7zi1x01VVQrXA5eLyG7gcqAfSLn7NqrqTuC1wD+LyLlu+/uBC4GnASuBG/J1LCJvdQXPrqGhoYoMvqc7OBNBPpVKMzQ6QchNlWwYhuGFkFt7vFDG7aVIJQVHPxDOet/tts2gqodV9VpVvQT4gNsWd//2u38PAfcBl7jvB9RhAvgSjkrsLFT1ZlXdqao7Ozs7yzqxDL3hIIcTSY4OJxkamUDVgv8MwyiNtQEfp6ZSDCerp4RsJQXH/cD5IrJZRFqA1wB3ZB8gIqtFJDOG9wNfdNtXZFRQIrIaeDbwsPt+rftXgGuAhyo4h6LMZMrtS2S54pqqyjAM71RjLEfFBIeqTgPvAO4C9gHfVNW9InKjiGS8pK4A9ovIAaALuMltvwjYJSJRHKP536vqw+6+r4rIHmAPsBr4SKXmMBsXrwvQ2CBEYidnyj9a1LhhGKWQifsaqKJYjqZKdq6qdwJ35rR9MGv7duD2POf9AtheoM8ryzzMOdPW0siFoQ6isQSr3Yp/pqoyDKMUQlVYe3yxjeNVT084SLQvzmAiSUtjAyvbWxZ7SIZhVBFrXE/MakqvboJjnvR2BxlJTvOLx47TFWjFMb0YhmF4o7WpkVXtLSY46oneDY6BfE9/wtRUhmHMiS6/z1RV9cS5nctpb3FyU5lh3DCMuRCqskqAJjjmSWODsMNNP2IrDsMw5kKXGwRYLZjgKAOZwk6WTt0wjLkQ8vs4PjbJxHRq9oOXABV1x60XesMBwFRVhmHMjUxdjqv/+Wc0NpTXweYLb3gaG1YtK2ufJjjKwOVb1vCW527meVsqk9rEMIza5vILOnn5JesrsuJoaSq/YkmqKbHWXNm5c6fu2rVrsYdhGIZRVYjIA26y2TMwG4dhGIZREiY4DMMwjJIwwWEYhmGUhAkOwzAMoyRMcBiGYRglYYLDMAzDKAkTHIZhGEZJmOAwDMMwSqIuAgBFZAh46NZN4wAAB0hJREFUMqd5NXBsEYZTKWptPlB7c7L5LH1qbU7znc9GVT0rJUZdCI58iMiufBGR1UqtzQdqb042n6VPrc2pUvMxVZVhGIZREiY4DMMwjJKoZ8Fx82IPoMzU2nyg9uZk81n61NqcKjKfurVxGIZhGHOjnlcchmEYxhwwwWEYhmGURN0JDhG5SkT2i8hBEXnfYo+nHIjIEyKyR0QiIlJ1FatE5IsiclREHspqWykid4vIo+7fFYs5xlIpMKcPiUi/+z1FROT3F3OMpSAiYRG5V0QeFpG9IvJOt70qv6ci86nm78gnIr8Rkag7p79z2zeLyK/de943RKRl3teqJxuHiDQCB4AXAH3A/cB1qvrwog5snojIE8BOVa3KwCUReR4wCtyqqtvcto8BJ1T1710Bv0JVb1jMcZZCgTl9CBhV1Y8v5tjmgoisBdaq6m9FpAN4ALgGeCNV+D0Vmc+rqN7vSIB2VR0VkWbg58A7gXcD31HV20Tk34Coqn52PteqtxXHZcBBVT2kqpPAbcDLFnlMdY+q/jdwIqf5ZcAt7vYtOP/UVUOBOVUtqjqgqr91t0eAfcB6qvR7KjKfqkUdRt23ze5LgSuB2932snxH9SY41gOxrPd9VPmPxUWBH4vIAyLy1sUeTJnoUtUBd3sQ6FrMwZSRd4jIg64qqyrUOrmIyCbgEuDX1MD3lDMfqOLvSEQaRSQCHAXuBh4D4qo67R5SlntevQmOWuU5qnopcDXwdldNUjOoo0+tBZ3qZ4FzgV5gAPjE4g6ndERkOfBt4F2qOpy9rxq/pzzzqervSFVTqtoLdONoWC6sxHXqTXD0A+Gs991uW1Wjqv3u36PAd3F+MNXOEVcPndFHH13k8cwbVT3i/mOngc9RZd+Tqzf/NvBVVf2O21y131O++VT7d5RBVePAvcAzgaCINLm7ynLPqzfBcT9wvutl0AK8Brhjkcc0L0Sk3TXuISLtwAuBh4qfVRXcAbzB3X4D8P1FHEtZyNxgXV5OFX1PruH1C8A+Vf2nrF1V+T0Vmk+Vf0edIhJ0t9twnID24QiQV7iHleU7qiuvKgDXve6fgUbgi6p60yIPaV6IyDk4qwyAJuBr1TYnEfk6cAVOCugjwP8Bvgd8E9iAkxL/VapaNcbmAnO6AkcFosATwNuy7ANLGhF5DvAzYA+Qdpv/GscuUHXfU5H5XEf1fkc7cIzfjTiLgm+q6o3uPeI2YCWwG3i9qk7M61r1JjgMwzCM+VFvqirDMAxjnpjgMAzDMErCBIdhGIZREiY4DMMwjJIwwWEYhmGUhAkOoyZwM52+KKftXSJSMJmbiNwnIjsrPK6vu+kr/iqn/UMicr277XMzy34oz/mvFJF9InLvPMYwmrX9+yJyQEQ2umMYF5E1BY5VEflE1vvr843RqD9McBi1wtdxAjqzeY3bviiISAh4mqruUNVPFjimBSd6+QFV/VCeQ94EvEVVn+/xmk1F9v0u8CngalV90m0+BrynwCkTwLUistrLtY36wQSHUSvcDrw4U2vATVy3DviZiHxWRHZl1yjIJedJ+xUi8mV3u1NEvi0i97uvZ+c51yciXxKnJspuEcnc5H8MrHfrOjw3z2WbgG8Aj6rqWbVhROSDwHOAL4jIPxa6joi8UUTuEJGfAPcUmN/zcFJovERVH8va9UXg1SKyMs9p0zg1q/8qzz6jjjHBYdQEbrTyb3ASPYKz2vimm3jvA6q6E9gBXO5G2HrlX4BPqurTgD8EPp/nmLc7Q9DtOJHHt4iID3gp8Jiq9qrqz/Kc97+BSVV9V4E53QjsAl6nqu8tch2AS4FXqOrlebpqxYnEv0ZVH8nZN4ojPN5ZYP6fAV4nIoEC+406xASHUUtkq6uy1VSvEpHf4qRbuBjYWkKfvwd82k1VfQfgdzOqZvMc4D8A3Bvzk8AWD33/HHiWiHg5drbr3F0k1ccU8AsctVc+PgW8IZPzLBs3Y+ytwF96HKNRB5jgMGqJ7wO/KyKXAstU9QER2QxcD/yuqu4Afgj48pybnXsne38D8Ax31dCrquuziuXMl/8G3gX8KCe53lwY+3/t3TFKA1EQgOF/0lgItt5AsNJCPIMgeAEbO220FvEIKlYeQSsRxEJsLMQDiCB6BEECNpbGYt5iWDbBR7r4f01YHsO+aiczb5kds/ZNftluNSIO2otlkuo5WdF0OSWTzuyEe9SUMHFoapQH+j3ZemmqjTnyofoZEfP8trLa3iNiMSJ65FTUxh2w21xExHJH7AOwWdYXyIF/b3/c8yVwBNw2k03HmOQ+X8A62XbqqjxOgG3y3KUd2ycHGY6qWPTPmDg0bS6ApfLLYDB4IltUr+S/6scRcfvADdnSGZ6GugeslFdqX4CdjtgzoBcRz+Rh91bN9NHy/ecr4HrozKLLpPfpA2vAYURstNY+yh5mRoQfk5N+JafjSpLqWHFIkqqYOCRJVUwckqQqJg5JUhUThySpiolDklTFxCFJqvID2MsJVuCTvFYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot how accuracy changes as we vary k\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.title(\"Variations in accuracy vs. k values\")\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH5N487j0G51"
   },
   "source": [
    "**`Observation and learnings`** :\n",
    "\n",
    "1. The maximum cv accuracy occurs from k=13 to k=20\n",
    "<br><br>\n",
    "2. The general shape of the curve is an upside down yield. This is quite typical when examining the model complexity and accuracy. This is an example of bias-variance trade off\n",
    "\n",
    "> **Low values of k (low bias, high variance)**<br>\n",
    "<font color=\"red\"> The 1-Nearest Neighbor classifier is the most complex nearest neighbor model\n",
    "It has the most jagged decision boundary, and is most likely to overfit </font>\n",
    "\n",
    "> **High values of k (high bias, low variance)**<br>\n",
    "<font color=\"red\"> underfit </font>\n",
    "\n",
    "> **Best value is the middle of k (most likely to generalize out-of-sample data)**<br>\n",
    "<font color=\"red\"> just right </font>\n",
    "\n",
    "> The best value of k<br>\n",
    "<font color=\"red\"> Higher values of k produce less complex model, So we will choose **20** as our best KNN model </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thc4wxt20G56"
   },
   "source": [
    "**Can You solve this ?**\n",
    "\n",
    "> Find the better of 2 models :  KNN or logistic regression when used for classifying on the iris dataset.\n",
    "\n",
    "`Note` : This is the <u>third application</u> of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8MYKa330G58",
    "outputId": "cddd0198-b139-40ed-cdaa-ada65304c781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# Goal: Compare the best KNN model with logistic regression on the iris dataset\n",
    "\n",
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)        ##  ML model 1\n",
    "\n",
    "# Instead of saving 10 scores in object named score and calculating mean\n",
    "# We're just calculating the mean directly on the results\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y1V4_RZ0G6A",
    "outputId": "4034225f-1b53-4746-b061-ecb1df6fb833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()                     ##  ML model 2\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So4Tx--s0G6H"
   },
   "source": [
    "**We can conclude that KNN is likely a better choice than logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBKfvUxQ0G6J"
   },
   "source": [
    "**Can You solve this ?**\n",
    "\n",
    "> Find the best features out of many fetures or simply said Applying CV for <u>feature selection</u>\n",
    "\n",
    "`Note` : This is the <u>fourth application</u> of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XMJUirW0G6M",
    "outputId": "905349ec-415b-49eb-d197-850d0eeb7473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TV  radio  newspaper  sales\n",
      "1  230.1   37.8       69.2   22.1\n",
      "2   44.5   39.3       45.1   10.4\n",
      "3   17.2   45.9       69.3    9.3\n",
      "4  151.5   41.3       58.5   18.5\n",
      "5  180.8   10.8       58.4   12.9\n",
      "------------No. of rows & columns------------------\n",
      "(200, 4)\n"
     ]
    }
   ],
   "source": [
    "# Goal: Select whether the Newspaper feature should be included in the linear regression model \n",
    "# on the advertising dataset or Not ????\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# read in the advertising dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/ingledarshan/BK_Birla/main/Advertising.csv', index_col=0)\n",
    "# data source : https://www.kaggle.com/sazid28/advertising.csv\n",
    "\n",
    "print(data.head()) # its quite obvious that sales would be the target variable\n",
    "print(\"------------No. of rows & columns------------------\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Cn7tbAhV0G6T"
   },
   "outputs": [],
   "source": [
    "# create a Python list of three feature names\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "\n",
    "# use the list to select a subset of the DataFrame (X)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# select the Sales column as the response (y)\n",
    "# since we're selecting only one column, we can select the attribute using .attribute\n",
    "y = data.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBeU7QTF0G6X",
    "outputId": "4a31d286-aeb4-4301-c9dc-bf05aa35f4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56038438 -3.29767522 -2.08943356 -2.82474283 -1.3027754  -1.74163618\n",
      " -8.17338214 -2.11409746 -3.04273109 -2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "# instantiate model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# store scores in scores object\n",
    "# we can't use accuracy as our evaluation metric since that's only relevant for classification problems\n",
    "# RMSE is not directly available so we will use MSE\n",
    "scores = cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "print(scores)\n",
    "\n",
    "# Please Note choosing scoring='mean_squared_error' would give us a deprecation Warning. \n",
    "# Hence I have selected scoring='neg_mean_squared_error'. You can try by self also.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ANg_WJ_0G6c"
   },
   "source": [
    "**MSE should be positive. But why is the MSE here negative?**\n",
    "\n",
    "> MSE is a <u>loss function</u>. It is something we want to <u>minimize</u>\n",
    "\n",
    "> A design decision was made so that the results are made negative. The best results would be the largest number (the least negative) so we can still maximize similar to classification accuracy\n",
    "\n",
    "> Classification Accuracy is a <u>reward function</u>. It is something we want to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhzmchT0G6e",
    "outputId": "e9fd99b2-4130-4308-ba74-2879d3ff2d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.56038438 3.29767522 2.08943356 2.82474283 1.3027754  1.74163618\n",
      " 8.17338214 2.11409746 3.04273109 2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# fix the sign of MSE scores\n",
    "mse_scores = -scores\n",
    "print(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eMvJVbW0G6i",
    "outputId": "e4923c8f-273c-4fa7-eb4f-44b12379dc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.88689808 1.81595022 1.44548731 1.68069713 1.14139187 1.31971064\n",
      " 2.85891276 1.45399362 1.7443426  1.56614748]\n"
     ]
    }
   ],
   "source": [
    "# convert from MSE to RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "print(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfIBVKy10G6u",
    "outputId": "da4f7252-6138-4a09-bbeb-42377ad3a864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6913531708051797\n"
     ]
    }
   ],
   "source": [
    "# calculate the average RMSE\n",
    "print(rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQdl04sW0G6z",
    "outputId": "8f683ec5-0d52-4ea4-b3e6-bb4d318e96f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6796748419090766\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with two features (excluding Newspaper)\n",
    "feature_cols = ['TV', 'radio']\n",
    "X = data[feature_cols]\n",
    "print(np.sqrt(-cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifdyl2wV0G63"
   },
   "source": [
    "**Without Newspaper, Average RMSE = 1.68\n",
    "<br><br>\n",
    "`lower number than with model with Newspaper`**\n",
    "\n",
    "> RMSE is something we want to <u>minimize</u>. **So the model excluding Newspaper is a better model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZDBcitO0G66"
   },
   "source": [
    "Resources\n",
    "--\n",
    "\n",
    "1. scikit-learn documentation: <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html\">Cross-validation</a>, \n",
    "<a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html\">Model evaluation</a>\n",
    "<br><br>\n",
    "2. scikit-learn issue on GitHub: <a href=\"https://github.com/scikit-learn/scikit-learn/issues/2439\">MSE is negative when returned by cross_val_score</a>\n",
    "<br><br> \n",
    "3. Scott Fortmann-Roe:  <a href=\"http://scott.fortmann-roe.com/docs/MeasuringError.html\">Accurately Measuring Model Prediction Error</a>\n",
    "<br><br> \n",
    "4. Machine Learning Mastery: <a href=\"https://machinelearningmastery.com/an-introduction-to-feature-selection/\">An Introduction to Feature Selection</a>\n",
    "<br><br> \n",
    "5. Harvard CS109: Cross-Validation: <a href=\" https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb\">The Right and Wrong Way</a>\n",
    "<br><br> \n",
    "6. Journal of Cheminformatics: <a href=\"https://jcheminf.biomedcentral.com/track/pdf/10.1186/1758-2946-6-10\">Cross-validation pitfalls when selecting and assessing regression and classification models</a>\n",
    "<br><br>\n",
    "7. www.kaggle.com for the datasets and many great notebooks\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTClOYGbhbU6"
   },
   "source": [
    "# Homework\n",
    "\n",
    ">Classification -> RandomForestClassifier\n",
    "\n",
    ">Regression -> AdaBoostRegressor\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Cross_Validation_What_When_and_How_to_implement_it_.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
